{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create the SparkSession Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('linear_regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Linear_regression_dataset.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(df):\n",
    "    # (row, columns)\n",
    "    return (df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|            var_1|            var_2|             var_3|               var_4|               var_5|             output|\n",
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|             1232|             1232|              1232|                1232|                1232|               1232|\n",
      "|   mean|715.0819805194806|715.0819805194806| 80.90422077922078|  0.3263311688311693| 0.25927272727272715|0.39734172077922014|\n",
      "| stddev| 91.5342940441652|93.07993263118064|11.458139049993724|0.015012772334166148|0.012907228928000298|0.03326689862173776|\n",
      "+-------+-----------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe the dataset.\n",
    "df.describe().show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(var_1=734, var_2=688, var_3=81, var_4=0.328, var_5=0.259, output=0.418),\n",
       " Row(var_1=700, var_2=600, var_3=94, var_4=0.32, var_5=0.247, output=0.389),\n",
       " Row(var_1=712, var_2=705, var_3=93, var_4=0.311, var_5=0.247, output=0.417)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 3 rows.\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "|corr(var_1, output)|corr(var_2, output)|corr(var_3, output)|corr(var_4, output)|corr(var_5, output)|\n",
      "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "| 0.9187399607627283|0.43652698913681093| 0.4014958408311139| 0.7909100204842113| 0.7904806260381185|\n",
      "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the covariance between var_1 and output.\n",
    "from pyspark.sql.functions import corr\n",
    "\n",
    "# var_1 seems to be most strongly correlated with the output column.\n",
    "df.select(*[corr(f'var_{i+1}', 'output') \n",
    "            for i in range(5)]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Feature Engineering\n",
    "\n",
    "Spark's `VectorAssembler` combines all input features and create only a single feature that captures the input values for that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'output']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- var_1: integer (nullable = true)\n",
      " |-- var_2: integer (nullable = true)\n",
      " |-- var_3: integer (nullable = true)\n",
      " |-- var_4: double (nullable = true)\n",
      " |-- var_5: double (nullable = true)\n",
      " |-- output: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['var_1', 'var_2', 'var_3', 'var_4', 'var_5'],\n",
    "                                outputCol='features')\n",
    "features_df = vec_assembler.transform(df)\n",
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|output|\n",
      "+--------------------+------+\n",
      "|[734.0,688.0,81.0...| 0.418|\n",
      "|[700.0,600.0,94.0...| 0.389|\n",
      "|[712.0,705.0,93.0...| 0.417|\n",
      "|[734.0,806.0,69.0...| 0.415|\n",
      "|[613.0,759.0,61.0...| 0.378|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To build the linear regression model, we just need the features and output column.\n",
    "model_df = features_df.select('features', 'output')\n",
    "model_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((855, 2), (377, 2))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = model_df.randomSplit([.7, .3], seed=42)\n",
    "shape(train_df), shape(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Build and train linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the \"output\" column as the label.\n",
    "lin_reg = LinearRegression(labelCol='output')\n",
    "\n",
    "# Fit the model to the train dataset.\n",
    "lr_model = lin_reg.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0003, 0.0001, 0.0002, -0.6292, 0.4952])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17778601018255152"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8749889968158224"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_predictions = lr_model.evaluate(train_df)\n",
    "training_predictions.r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate Linear Regression Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8547754016343414, 0.00015731589773936277)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = lr_model.evaluate(test_df)\n",
    "test_predictions.r2, test_predictions.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
