{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create the Spark Session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('log_reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Log_Reg_dataset.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape(df):\n",
    "    return (df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Repeat_Visitor: integer (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Web_pages_viewed: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
      "|summary| Country|              Age|   Repeat_Visitor|Platform| Web_pages_viewed|            Status|\n",
      "+-------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
      "|  count|   20000|            20000|            20000|   20000|            20000|             20000|\n",
      "|   mean|    null|         28.53955|           0.5029|    null|           9.5533|               0.5|\n",
      "| stddev|    null|7.888912950773227|0.500004090187782|    null|6.073903499824976|0.5000125004687693|\n",
      "|    min|  Brazil|               17|                0|    Bing|                1|                 0|\n",
      "|    max|Malaysia|              111|                1|   Yahoo|               29|                 1|\n",
      "+-------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------+--------+----------------+------+\n",
      "|  Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|\n",
      "+---------+---+--------------+--------+----------------+------+\n",
      "|    India| 41|             1|   Yahoo|              21|     1|\n",
      "|   Brazil| 28|             1|   Yahoo|               5|     0|\n",
      "|   Brazil| 40|             0|  Google|               3|     0|\n",
      "|Indonesia| 31|             1|    Bing|              15|     1|\n",
      "| Malaysia| 32|             0|  Google|              15|     1|\n",
      "+---------+---+--------------+--------+----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  Country|count|\n",
      "+---------+-----+\n",
      "| Malaysia| 1218|\n",
      "|    India| 4018|\n",
      "|Indonesia|12178|\n",
      "|   Brazil| 2586|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Platform|count|\n",
      "+--------+-----+\n",
      "|   Yahoo| 9859|\n",
      "|    Bing| 4360|\n",
      "|  Google| 5781|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Platform').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1|10000|\n",
      "|     0|10000|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Status').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-------------------+---------------------+--------------------+\n",
      "|  Country|          avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|         avg(Status)|\n",
      "+---------+------------------+-------------------+---------------------+--------------------+\n",
      "| Malaysia|27.792282430213465| 0.5730706075533661|   11.192118226600986|  0.6568144499178982|\n",
      "|    India|27.976854156296664| 0.5433051269288203|   10.727227476356397|  0.6212045793927327|\n",
      "|Indonesia| 28.43159796354081| 0.5207751683363442|    9.985711939563148|  0.5422893742814913|\n",
      "|   Brazil|30.274168600154677|  0.322892498066512|    4.921113689095128|0.038669760247486466|\n",
      "+---------+------------------+-------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------------+---------------------+-----------+\n",
      "|Status|avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|avg(Status)|\n",
      "+------+--------+-------------------+---------------------+-----------+\n",
      "|     1| 26.5435|             0.7019|              14.5617|        1.0|\n",
      "|     0| 30.5356|             0.3039|               4.5449|        0.0|\n",
      "+------+--------+-------------------+---------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Status').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Feature Engineering\n",
    "\n",
    "Convert categorical variable into numerical form using `StringIndexer`, and create a single vector combining all the input features by using Spark's `VectorAssembler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_indexer = StringIndexer(inputCol='Platform', outputCol='Platform_Num').fit(df)\n",
    "df = search_engine_indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------+--------+----------------+------+------------+\n",
      "|  Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_Num|\n",
      "+---------+---+--------------+--------+----------------+------+------------+\n",
      "|    India| 41|             1|   Yahoo|              21|     1|         0.0|\n",
      "|   Brazil| 28|             1|   Yahoo|               5|     0|         0.0|\n",
      "|   Brazil| 40|             0|  Google|               3|     0|         1.0|\n",
      "|Indonesia| 31|             1|    Bing|              15|     1|         2.0|\n",
      "| Malaysia| 32|             0|  Google|              15|     1|         1.0|\n",
      "+---------+---+--------------+--------+----------------+------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Platform|count|\n",
      "+--------+-----+\n",
      "|   Yahoo| 9859|\n",
      "|  Google| 5781|\n",
      "|    Bing| 4360|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Platform').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|Platform_Num|count|\n",
      "+------------+-----+\n",
      "|         0.0| 9859|\n",
      "|         1.0| 5781|\n",
      "|         2.0| 4360|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Platform_Num').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent each of the values into the form of one hot encoded vector.\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "search_engine_encoder = OneHotEncoder(inputCol='Platform_Num', outputCol='Platform_Vector')\n",
    "df = search_engine_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_Num|Platform_Vector|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "|  India| 41|             1|   Yahoo|              21|     1|         0.0|  (2,[0],[1.0])|\n",
      "| Brazil| 28|             1|   Yahoo|               5|     0|         0.0|  (2,[0],[1.0])|\n",
      "| Brazil| 40|             0|  Google|               3|     0|         1.0|  (2,[1],[1.0])|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|Platform_Vector|count|\n",
      "+---------------+-----+\n",
      "|  (2,[0],[1.0])| 9859|\n",
      "|  (2,[1],[1.0])| 5781|\n",
      "|      (2,[],[])| 4360|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Platform_Vector').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same for Country column.\n",
    "country_indexer = StringIndexer(inputCol='Country', outputCol='Country_Num').fit(df)\n",
    "df = country_indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  Country|count|\n",
      "+---------+-----+\n",
      "|Indonesia|12178|\n",
      "|    India| 4018|\n",
      "|   Brazil| 2586|\n",
      "| Malaysia| 1218|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Country_Num|count|\n",
      "+-----------+-----+\n",
      "|        0.0|12178|\n",
      "|        1.0| 4018|\n",
      "|        2.0| 2586|\n",
      "|        3.0| 1218|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country_Num').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_encoder = OneHotEncoder(inputCol='Country_Num', outputCol='Country_Vector')\n",
    "df = country_encoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|Country|Country_Num|Country_Vector|\n",
      "+-------+-----------+--------------+\n",
      "|  India|        1.0| (3,[1],[1.0])|\n",
      "| Brazil|        2.0| (3,[2],[1.0])|\n",
      "| Brazil|        2.0| (3,[2],[1.0])|\n",
      "+-------+-----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Country', 'Country_Num', 'Country_Vector']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Country_Vector|count|\n",
      "+--------------+-----+\n",
      "| (3,[0],[1.0])|12178|\n",
      "| (3,[1],[1.0])| 4018|\n",
      "| (3,[2],[1.0])| 2586|\n",
      "|     (3,[],[])| 1218|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country_Vector').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country',\n",
       " 'Age',\n",
       " 'Repeat_Visitor',\n",
       " 'Platform',\n",
       " 'Web_pages_viewed',\n",
       " 'Status',\n",
       " 'Platform_Num',\n",
       " 'Platform_Vector',\n",
       " 'Country_Num',\n",
       " 'Country_Vector']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assembler = VectorAssembler(inputCols=['Platform_Vector', 'Country_Vector', 'Age', 'Repeat_Visitor', 'Web_pages_viewed'],\n",
    "                               outputCol='features')\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Repeat_Visitor: integer (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Web_pages_viewed: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- Platform_Num: double (nullable = false)\n",
      " |-- Platform_Vector: vector (nullable = true)\n",
      " |-- Country_Num: double (nullable = false)\n",
      " |-- Country_Vector: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|Status|\n",
      "+--------------------+------+\n",
      "|[1.0,0.0,0.0,1.0,...|     1|\n",
      "|[1.0,0.0,0.0,0.0,...|     0|\n",
      "|(8,[1,4,5,7],[1.0...|     0|\n",
      "|(8,[2,5,6,7],[1.0...|     1|\n",
      "|(8,[1,5,7],[1.0,3...|     1|\n",
      "|(8,[1,4,5,7],[1.0...|     0|\n",
      "|(8,[1,4,5,7],[1.0...|     0|\n",
      "|(8,[1,2,5,7],[1.0...|     0|\n",
      "|(8,[0,2,5,7],[1.0...|     0|\n",
      "|(8,[2,5,6,7],[1.0...|     1|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['features', 'Status']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = df.select(['features', 'Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15001, 2), (4999, 2))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = model_df.randomSplit([.75, .25])\n",
    "shape(train_df), shape(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1| 7472|\n",
      "|     0| 7529|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure we have a balance dataset.\n",
    "train_df.groupBy('Status').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1| 2528|\n",
      "|     0| 2471|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.groupBy('Status').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Build and Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(labelCol='Status').fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+\n",
      "|Status|prediction|         probability|\n",
      "+------+----------+--------------------+\n",
      "|     1|       1.0|[0.30709238167482...|\n",
      "|     1|       1.0|[0.17206932221585...|\n",
      "|     1|       1.0|[0.17206932221585...|\n",
      "|     1|       1.0|[0.17206932221585...|\n",
      "|     1|       1.0|[0.08880484143428...|\n",
      "|     1|       1.0|[0.08880484143428...|\n",
      "|     1|       1.0|[0.08880484143428...|\n",
      "|     1|       1.0|[0.08880484143428...|\n",
      "|     1|       1.0|[0.04370517002470...|\n",
      "|     1|       1.0|[0.04370517002470...|\n",
      "+------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results = log_reg.evaluate(train_df).predictions\n",
    "train_results.filter(train_results['Status'] == 1).filter(train_results['prediction'] == 1).select(['Status', 'prediction', 'probability']).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate Linear Regression Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = log_reg.evaluate(test_df).predictions\n",
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Status|prediction|\n",
      "+------+----------+\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "|     0|       0.0|\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(['Status', 'prediction']).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = results[(results.Status == 1) & (results.prediction == 1)].count()\n",
    "tn = results[(results.Status == 0) & (results.prediction == 0)].count()\n",
    "fp = results[(results.Status == 0) & (results.prediction == 1)].count()\n",
    "fn = results[(results.Status == 1) & (results.prediction == 0)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363872774554911"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = float((tp + tn) / results.count())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9291930379746836"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = float(tp) / (tp + fn)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9441318327974276"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = float(tp) / (tp + fp)\n",
    "precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
